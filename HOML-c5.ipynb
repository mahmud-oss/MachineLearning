{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "'How to tokenize?\\nLike a boss.',\n",
    "'Google is accessible via http://www.google.com',\n",
    "'1000 new followers! #TwitterFamous',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "split() not efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'to', 'tokenize?', 'Like', 'a', 'boss.']\n",
      "['Google', 'is', 'accessible', 'via', 'http://www.google.com']\n",
      "['1000', 'new', 'followers!', '#TwitterFamous']\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    print(line.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "_token_pattern=r\"\\w+\"\n",
    "token_pattern=re.compile(_token_pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'\\w+', re.UNICODE)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['How', 'to', 'tokenize', 'Like', 'a', 'boss']\n",
      "['Google', 'is', 'accessible', 'via', 'http', 'www', 'google', 'com']\n",
      "['1000', 'new', 'followers', 'TwitterFamous']\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    print(token_pattern.findall(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using placeholders before tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'to', 'tokenize', 'like', 'a', 'boss']\n",
      "['google', 'is', 'accessible', 'via', '_url_']\n",
      "['_num_', 'new', 'followers', '_hashtag_']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "_token_pattern=r\"\\w+\"\n",
    "token_pattern=re.compile(_token_pattern)\n",
    "def tokenizer(line):\n",
    "    line=line.lower()\n",
    "    line=re.sub(r\"https?:\\/\\/www\\.[A-Z a-z 0-9]+\\.[A-Z a-z]+\",'_url_',line)\n",
    "    line=re.sub(r'#\\w+', '_hashtag_', line)\n",
    "    line=re.sub(r'\\d+','_num_', line)\n",
    "    return token_pattern.findall(line)\n",
    "for line in lines:\n",
    "    print(tokenizer(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "positive lookbehind(taking the hashtag value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "['TwitterFamous']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "_token_pattern=r\"(?<=#)\\w+\"\n",
    "token_pattern=re.compile(_token_pattern)\n",
    "for line in lines:\n",
    "    print(token_pattern.findall(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vector Space Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) beg of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = [\n",
    "'How to tokenize?\\nLike a boss.',\n",
    "'Google is accessible via http://www.google.com',\n",
    "'1000 new followers! #TwitterFamous',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['how', 'to', 'tokenize', 'like', 'a', 'boss']\n",
      "['google', 'is', 'accessible', 'via', '_url_']\n",
      "['_num_', 'new', 'followers', '_hashtag_']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "_token_pattern=r\"\\w+\"\n",
    "token_pattern=re.compile(_token_pattern)\n",
    "def tokenizer(line):\n",
    "    line=line.lower()\n",
    "    line=re.sub(r\"https?:\\/\\/www\\.[A-Z a-z 0-9]+\\.[A-Z a-z]+\",'_url_',line)\n",
    "    line=re.sub(r'#\\w+', '_hashtag_', line)\n",
    "    line=re.sub(r'\\d+','_num_', line)\n",
    "    return token_pattern.findall(line)\n",
    "for line in lines:\n",
    "    print(tokenizer(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to tokenize?\\nLike a boss.',\n",
       " 'Google is accessible via http://www.google.com',\n",
       " '1000 new followers! #TwitterFamous']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec=CountVectorizer(lowercase=True, tokenizer=tokenizer)\n",
    "x=vec.fit_transform(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t1\n",
      "  (0, 12)\t1\n",
      "  (0, 13)\t1\n",
      "  (0, 10)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 14)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 11)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_hashtag_</th>\n",
       "      <th>_num_</th>\n",
       "      <th>_url_</th>\n",
       "      <th>a</th>\n",
       "      <th>accessible</th>\n",
       "      <th>boss</th>\n",
       "      <th>followers</th>\n",
       "      <th>google</th>\n",
       "      <th>how</th>\n",
       "      <th>is</th>\n",
       "      <th>like</th>\n",
       "      <th>new</th>\n",
       "      <th>to</th>\n",
       "      <th>tokenize</th>\n",
       "      <th>via</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _hashtag_  _num_  _url_  a  accessible  boss  followers  google  how  is  \\\n",
       "0          0      0      0  1           0     1          0       0    1   0   \n",
       "1          0      0      1  0           1     0          0       1    0   1   \n",
       "2          1      1      0  0           0     0          1       0    0   0   \n",
       "\n",
       "   like  new  to  tokenize  via  \n",
       "0     1    0   1         1    0  \n",
       "1     0    0   0         0    1  \n",
       "2     0    1   0         0    0  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(\n",
    "    x.todense(),\n",
    "    columns=vec.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ii) NGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_delayed_lines = [\n",
    "'Flight was delayed, I am not happy',\n",
    "'Flight was not delayed, I am happy'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec=CountVectorizer(ngram_range = (2,2))\n",
    "x=vec.fit_transform(flight_delayed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 3)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 2)\t1\n",
      "  (0, 1)\t1\n",
      "  (0, 5)\t1\n",
      "  (1, 3)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 7)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 0)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am happy</th>\n",
       "      <th>am not</th>\n",
       "      <th>delayed am</th>\n",
       "      <th>flight was</th>\n",
       "      <th>not delayed</th>\n",
       "      <th>not happy</th>\n",
       "      <th>was delayed</th>\n",
       "      <th>was not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   am happy  am not  delayed am  flight was  not delayed  not happy  \\\n",
       "0         0       1           1           1            0          1   \n",
       "1         1       0           1           1            1          0   \n",
       "\n",
       "   was delayed  was not  \n",
       "0            1        0  \n",
       "1            0        1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(\n",
    "    x.todense(),\n",
    "    columns=vec.get_feature_names()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "characters as token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Flight was delayed, I am not happy', 'Flight was not delayed, I am happy']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_delayed_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=CountVectorizer(ngram_range=(4,4),analyzer='char')\n",
    "x=vec.fit_transform(flight_delayed_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>am</th>\n",
       "      <th>del</th>\n",
       "      <th>hap</th>\n",
       "      <th>i a</th>\n",
       "      <th>not</th>\n",
       "      <th>was</th>\n",
       "      <th>, i</th>\n",
       "      <th>am h</th>\n",
       "      <th>am n</th>\n",
       "      <th>appy</th>\n",
       "      <th>...</th>\n",
       "      <th>not</th>\n",
       "      <th>ot d</th>\n",
       "      <th>ot h</th>\n",
       "      <th>s de</th>\n",
       "      <th>s no</th>\n",
       "      <th>t de</th>\n",
       "      <th>t ha</th>\n",
       "      <th>t wa</th>\n",
       "      <th>was</th>\n",
       "      <th>yed,</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    am    del   hap   i a   not   was  , i   am h  am n  appy  ...  not   \\\n",
       "0     1     1     1     1     1     1     1     0     1     1  ...     1   \n",
       "1     1     1     1     1     1     1     1     1     0     1  ...     1   \n",
       "\n",
       "   ot d  ot h  s de  s no  t de  t ha  t wa  was   yed,  \n",
       "0     0     1     1     0     0     1     1     1     1  \n",
       "1     1     0     0     1     1     0     1     1     1  \n",
       "\n",
       "[2 rows x 37 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(\n",
    "    \n",
    "        x.todense(),\n",
    "        columns=vec.get_feature_names()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "important word counting using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines_fruits = [\n",
    "'I like apples',\n",
    "'I like oranges',\n",
    "'I like pears',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like apples', 'I like oranges', 'I like pears']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_fruits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec=TfidfVectorizer(token_pattern=r'\\w+')\n",
    "x=vec.fit_transform(lines_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like apples', 'I like oranges', 'I like pears']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines_fruits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec1=CountVectorizer(ngram_range=(1,1))\n",
    "x1=vec1.fit_transform(lines_fruits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t1\n",
      "  (0, 0)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t0.7674945674619879\n",
      "  (0, 2)\t0.4532946552278861\n",
      "  (0, 1)\t0.4532946552278861\n",
      "  (1, 3)\t0.7674945674619879\n",
      "  (1, 2)\t0.4532946552278861\n",
      "  (1, 1)\t0.4532946552278861\n",
      "  (2, 4)\t0.7674945674619879\n",
      "  (2, 2)\t0.4532946552278861\n",
      "  (2, 1)\t0.4532946552278861\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.DataFrame(\n",
    "    x.todense(),\n",
    "    columns=vec.get_feature_names(),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1=pd.DataFrame(\n",
    "    x1.todense(),\n",
    "    columns=vec1.get_feature_names(),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apples</th>\n",
       "      <th>like</th>\n",
       "      <th>oranges</th>\n",
       "      <th>pears</th>\n",
       "      <th>apples</th>\n",
       "      <th>i</th>\n",
       "      <th>like</th>\n",
       "      <th>oranges</th>\n",
       "      <th>pears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apples  like  oranges  pears    apples         i      like   oranges  \\\n",
       "0       1     1        0      0  0.767495  0.453295  0.453295  0.000000   \n",
       "1       0     1        1      0  0.000000  0.453295  0.453295  0.767495   \n",
       "2       0     1        0      1  0.000000  0.453295  0.453295  0.000000   \n",
       "\n",
       "      pears  \n",
       "0  0.000000  \n",
       "1  0.000000  \n",
       "2  0.767495  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([df1, df], axis=1, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load('en_core_web_lg')\n",
    "terms=['I','like','apples','oranges','pears']\n",
    "vectors = [\n",
    "    nlp(term).vector.tolist() for term in terms\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 300)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(vectors).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>like</th>\n",
       "      <th>apples</th>\n",
       "      <th>oranges</th>\n",
       "      <th>pears</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.555491</td>\n",
       "      <td>0.204427</td>\n",
       "      <td>0.188241</td>\n",
       "      <td>0.118992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.555491</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.329871</td>\n",
       "      <td>0.277175</td>\n",
       "      <td>0.189569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apples</th>\n",
       "      <td>0.204427</td>\n",
       "      <td>0.329871</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.778094</td>\n",
       "      <td>0.839106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oranges</th>\n",
       "      <td>0.188241</td>\n",
       "      <td>0.277175</td>\n",
       "      <td>0.778094</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pears</th>\n",
       "      <td>0.118992</td>\n",
       "      <td>0.189569</td>\n",
       "      <td>0.839106</td>\n",
       "      <td>0.775538</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                I      like    apples   oranges     pears\n",
       "I        1.000000  0.555491  0.204427  0.188241  0.118992\n",
       "like     0.555491  1.000000  0.329871  0.277175  0.189569\n",
       "apples   0.204427  0.329871  1.000000  0.778094  0.839106\n",
       "oranges  0.188241  0.277175  0.778094  1.000000  0.775538\n",
       "pears    0.118992  0.189569  0.839106  0.775538  1.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "pd.DataFrame(\n",
    "    cosine_similarity(vectors),\n",
    "    index=terms,columns=terms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = f'{os.getcwd()}/text_dataset'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url ='https://archive.ics.uci.edu/ml/machine-learning-databases/00331/sentiment%20labelled%20sentences.zip'\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "from io import BytesIO\n",
    "with zipfile.ZipFile(file=BytesIO(response.content), mode='r') as compressed_file:\n",
    "    compressed_file.extractall(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_dir = f'{os.getcwd()}/text_dataset'\n",
    "df_list = []\n",
    "for csv_file in ['imdb_labelled.txt', 'yelp_labelled.txt','amazon_cells_labelled.txt']:\n",
    "    csv_file_with_path = f'{data_dir}/sentiment labelled sentences/{csv_file}'\n",
    "    temp_df = pd.read_csv(\n",
    "        csv_file_with_path,sep=\"\\t\", header=0,\n",
    "        names=['text', 'sentiment']\n",
    "    )\n",
    "    df_list.append(temp_df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='sentiment'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "explode = [0.01, 0.01]\n",
    "colors = ['#777777', '#660086']\n",
    "df['sentiment'].value_counts().plot(\n",
    "    kind='pie', colors=colors, explode=explode\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The rest of the movie lacks art, charm, meanin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wasted two hours.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Not sure who was more lost - the flat characte...          0\n",
       "1  Attempting artiness with black & white and cle...          0\n",
       "2       Very little music or anything to speak of.            0\n",
       "3  The best scene in the movie was when Gerardo i...          1\n",
       "4  The rest of the movie lacks art, charm, meanin...          0\n",
       "5                                Wasted two hours.            0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>This is a stunning movie.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>I had the mac salad and it was pretty bland so I will not be getting that again.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The food, amazing.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>Audio Quality is poor, very poor.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>His acting alongside Olivia De Havilland was brilliant and the ending was fantastic!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                       text  \\\n",
       "471                                                             This is a stunning movie.     \n",
       "278        I had the mac salad and it was pretty bland so I will not be getting that again.   \n",
       "20                                                                       The food, amazing.   \n",
       "150                                                       Audio Quality is poor, very poor.   \n",
       "430  His acting alongside Olivia De Havilland was brilliant and the ending was fantastic!     \n",
       "\n",
       "     sentiment  \n",
       "471          1  \n",
       "278          0  \n",
       "20           1  \n",
       "150          0  \n",
       "430          1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 90\n",
    "df[['text', 'sentiment']].sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_dir = f'{os.getcwd()}/text_dataset'\n",
    "df_list = []\n",
    "for csv_file in ['imdb_labelled.txt', 'yelp_labelled.txt','amazon_cells_labelled.txt']:\n",
    "    csv_file_with_path = f'{data_dir}/sentiment labelled sentences/{csv_file}'\n",
    "    temp_df = pd.read_csv(\n",
    "        csv_file_with_path,sep=\"\\t\", header=0,\n",
    "        names=['text', 'sentiment']\n",
    "    )\n",
    "    df_list.append(temp_df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(df, test_size=0.4,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=df_train['sentiment']\n",
    "y_test=df_test['sentiment']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec=CountVectorizer(ngram_range=(1,3),min_df=3,strip_accents='ascii')\n",
    "x_train=vec.fit_transform(df_train['text'])\n",
    "x_test=vec.transform(df_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB(fit_prior=True)\n",
    "clf.fit(x_train,y_train)\n",
    "y_test_predict = clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuple \\ an object \\ a sentence can be of multi-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.805861</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.792079</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.773551</td>\n",
       "      <td>0.801126</td>\n",
       "      <td>0.787097</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision    recall    fscore  support\n",
       "negative   0.805861  0.778761  0.792079      565\n",
       "positive   0.773551  0.801126  0.787097      533"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        'precision':s[0],\n",
    "        'recall':s[1],\n",
    "        'fscore':s[2],\n",
    "        'support':s[3]\n",
    "    },\n",
    "    index=['negative','positive']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7896174863387978"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_test_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes using tfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>fscore</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>0.825137</td>\n",
       "      <td>0.801770</td>\n",
       "      <td>0.813285</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.795993</td>\n",
       "      <td>0.819887</td>\n",
       "      <td>0.807763</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          precision    recall    fscore  support\n",
       "negative   0.825137  0.801770  0.813285      565\n",
       "positive   0.795993  0.819887  0.807763      533"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# vec=TfidfVectorizer(ngram_range=(1,3),min_df=3,strip_accents='ascii')\n",
    "vec = TfidfVectorizer(token_pattern=r'\\w+')\n",
    "x_train=vec.fit_transform(df_train['text'])\n",
    "x_test=vec.transform(df_test['text'])\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf=MultinomialNB(fit_prior=True)\n",
    "clf.fit(x_train,y_train)\n",
    "y_test_predict = clf.predict(x_test)\n",
    "s=score(y_test,y_test_predict)\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        'precision':s[0],\n",
    "        'recall':s[1],\n",
    "        'fscore':s[2],\n",
    "        'support':s[3]\n",
    "    },\n",
    "    index=['negative','positive']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "data_dir = f'{os.getcwd()}/text_dataset'\n",
    "df_list = []\n",
    "for csv_file in ['imdb_labelled.txt', 'yelp_labelled.txt','amazon_cells_labelled.txt']:\n",
    "    csv_file_with_path = f'{data_dir}/sentiment labelled sentences/{csv_file}'\n",
    "    temp_df = pd.read_csv(\n",
    "        csv_file_with_path,sep=\"\\t\", header=0,\n",
    "        names=['text', 'sentiment']\n",
    "    )\n",
    "    df_list.append(temp_df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test=train_test_split(df,test_size=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  sentiment\n",
       "0  Not sure who was more lost - the flat characte...          0\n",
       "1  Attempting artiness with black & white and cle...          0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=df_train['text']\n",
    "y_train=df_train['sentiment']\n",
    "x_test=df_test['text']\n",
    "y_test=df_test['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe=Pipeline(steps=[\n",
    "('CountVectorizer', CountVectorizer()),\n",
    "('MultinomialNB', MultinomialNB())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('CountVectorizer', CountVectorizer()),\n",
       "                ('MultinomialNB', MultinomialNB())])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7877959927140255"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
